{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOglCjhCJNYZ40nFsFskAh3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sumant-crty/Python-Data-Scraping-Portfolio/blob/main/MSNMB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install feedparser requests beautifulsoup4\n",
        "import feedparser\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "class BengaliNewsAggregator:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the news aggregator with multiple sources\"\"\"\n",
        "        self.rss_sources = {\n",
        "            # Google News - Bengali\n",
        "            'Google News - Bengal': 'https://news.google.com/rss/search?q=bengal+OR+kolkata&hl=bn&gl=IN&ceid=IN:bn',\n",
        "            'Google News - India (Bengali)': 'https://news.google.com/rss/search?q=india&hl=bn&gl=IN&ceid=IN:bn',\n",
        "            'Google News - West Bengal': 'https://news.google.com/rss/search?q=west+bengal&hl=en&gl=IN&ceid=IN:en',\n",
        "\n",
        "            # English News RSS\n",
        "            'The Telegraph Bengal': 'https://www.telegraphindia.com/feeds/rss/bengal',\n",
        "            'The Hindu - West Bengal': 'https://www.thehindu.com/news/national/west-bengal/feeder/default.rss',\n",
        "            'Times of India - Kolkata': 'https://timesofindia.indiatimes.com/rssfeeds/2279055.cms',\n",
        "            'Indian Express - Kolkata': 'https://indianexpress.com/section/cities/kolkata/feed/',\n",
        "            'NDTV - Kolkata': 'https://feeds.feedburner.com/ndtv/TIXd',\n",
        "\n",
        "            # National News RSS\n",
        "            'The Hindu - National': 'https://www.thehindu.com/news/national/feeder/default.rss',\n",
        "            'Times of India - India': 'https://timesofindia.indiatimes.com/rssfeeds/-2128936835.cms',\n",
        "            'India Today': 'https://www.indiatoday.in/rss/home',\n",
        "            'NDTV News': 'https://feeds.feedburner.com/ndtvnews-latest',\n",
        "            'Hindustan Times': 'https://www.hindustantimes.com/feeds/rss/india-news/rssfeed.xml',\n",
        "            'The Indian Express': 'https://indianexpress.com/feed/',\n",
        "\n",
        "            # Business & Economy\n",
        "            'Economic Times': 'https://economictimes.indiatimes.com/rssfeedstopstories.cms',\n",
        "            'Business Standard': 'https://www.business-standard.com/rss/home_page_top_stories.rss',\n",
        "            'Mint': 'https://www.livemint.com/rss/news',\n",
        "\n",
        "            # Sports\n",
        "            'Sports - Times of India': 'https://timesofindia.indiatimes.com/rssfeeds/4719148.cms',\n",
        "            'Cricket News': 'https://www.thehindu.com/sport/cricket/feeder/default.rss',\n",
        "\n",
        "            # Technology\n",
        "            'Tech News India': 'https://indianexpress.com/section/technology/feed/',\n",
        "        }\n",
        "\n",
        "        self.scraping_sources = [\n",
        "            {\n",
        "                'name': 'Ei Samay',\n",
        "                'url': 'https://eisamay.com/',\n",
        "                'method': self.scrape_eisamay\n",
        "            },\n",
        "            {\n",
        "                'name': 'Sangbad Pratidin',\n",
        "                'url': 'https://www.sangbadpratidin.in/',\n",
        "                'method': self.scrape_sangbad_pratidin\n",
        "            },\n",
        "            {\n",
        "                'name': 'ABP Ananda',\n",
        "                'url': 'https://www.abpananda.com/',\n",
        "                'method': self.scrape_abp_ananda\n",
        "            },\n",
        "            {\n",
        "                'name': 'Zee 24 Ghanta',\n",
        "                'url': 'https://zeenews.india.com/bengali',\n",
        "                'method': self.scrape_zee24ghanta\n",
        "            },\n",
        "            {\n",
        "                'name': 'News18 Bengali',\n",
        "                'url': 'https://bengali.news18.com/',\n",
        "                'method': self.scrape_news18_bengali\n",
        "            },\n",
        "            {\n",
        "                'name': 'The Telegraph Kolkata',\n",
        "                'url': 'https://www.telegraphindia.com/west-bengal',\n",
        "                'method': self.scrape_telegraph\n",
        "            },\n",
        "            {\n",
        "                'name': 'Bengal Live',\n",
        "                'url': 'https://bengallive.com/',\n",
        "                'method': self.scrape_bengal_live\n",
        "            },\n",
        "            {\n",
        "                'name': 'Bartaman Patrika',\n",
        "                'url': 'https://bartamanpatrika.com/',\n",
        "                'method': self.scrape_bartaman\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        self.headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
        "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
        "            'Accept-Language': 'en-US,en;q=0.5',\n",
        "            'Connection': 'keep-alive',\n",
        "        }\n",
        "\n",
        "    def fetch_rss_feed(self, url, source_name):\n",
        "        \"\"\"Fetch news from RSS feed\"\"\"\n",
        "        headlines = []\n",
        "        try:\n",
        "            print(f\"Fetching from {source_name}...\")\n",
        "            feed = feedparser.parse(url)\n",
        "\n",
        "            if feed.bozo:\n",
        "                print(f\"  Warning: Feed parsing issue for {source_name}\")\n",
        "\n",
        "            for entry in feed.entries[:20]:  # Get top 20 from each source\n",
        "                title = entry.get('title', 'No title')\n",
        "                link = entry.get('link', '#')\n",
        "                published = entry.get('published', entry.get('updated', 'Recent'))\n",
        "\n",
        "                headlines.append({\n",
        "                    'title': title,\n",
        "                    'link': link,\n",
        "                    'source': source_name,\n",
        "                    'published': published\n",
        "                })\n",
        "\n",
        "            print(f\"  ‚úì Found {len(headlines)} headlines from {source_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚úó Error fetching {source_name}: {str(e)}\")\n",
        "\n",
        "        return headlines\n",
        "\n",
        "    def scrape_eisamay(self, url):\n",
        "        \"\"\"Scrape Ei Samay\"\"\"\n",
        "        headlines = []\n",
        "        try:\n",
        "            response = requests.get(url, headers=self.headers, timeout=10)\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            # Try multiple selectors\n",
        "            selectors = ['h2 a', 'h3 a', '.headline a', 'article a']\n",
        "            for selector in selectors:\n",
        "                articles = soup.select(selector)\n",
        "                for article in articles[:20]:\n",
        "                    title = article.get_text(strip=True)\n",
        "                    link = article.get('href', '')\n",
        "\n",
        "                    if link and not link.startswith('http'):\n",
        "                        link = 'https://eisamay.com' + link\n",
        "\n",
        "                    if title and len(title) > 15 and link:\n",
        "                        headlines.append({\n",
        "                            'title': title,\n",
        "                            'link': link,\n",
        "                            'source': 'Ei Samay',\n",
        "                            'published': 'Recent'\n",
        "                        })\n",
        "\n",
        "                if len(headlines) >= 15:\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error: {str(e)}\")\n",
        "\n",
        "        return headlines[:15]\n",
        "\n",
        "    def scrape_sangbad_pratidin(self, url):\n",
        "        \"\"\"Scrape Sangbad Pratidin\"\"\"\n",
        "        headlines = []\n",
        "        try:\n",
        "            response = requests.get(url, headers=self.headers, timeout=10)\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            articles = soup.find_all(['h2', 'h3', 'h4'])\n",
        "            for article in articles:\n",
        "                link_tag = article.find('a')\n",
        "                if link_tag:\n",
        "                    title = link_tag.get_text(strip=True)\n",
        "                    link = link_tag.get('href', '')\n",
        "\n",
        "                    if link and not link.startswith('http'):\n",
        "                        link = 'https://www.sangbadpratidin.in' + link\n",
        "\n",
        "                    if title and len(title) > 15:\n",
        "                        headlines.append({\n",
        "                            'title': title,\n",
        "                            'link': link,\n",
        "                            'source': 'Sangbad Pratidin',\n",
        "                            'published': 'Recent'\n",
        "                        })\n",
        "\n",
        "                if len(headlines) >= 15:\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error: {str(e)}\")\n",
        "\n",
        "        return headlines\n",
        "\n",
        "    def scrape_abp_ananda(self, url):\n",
        "        \"\"\"Scrape ABP Ananda\"\"\"\n",
        "        headlines = []\n",
        "        try:\n",
        "            response = requests.get(url, headers=self.headers, timeout=10)\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            articles = soup.find_all('a', href=True)\n",
        "            for article in articles:\n",
        "                title = article.get_text(strip=True)\n",
        "                link = article.get('href', '')\n",
        "\n",
        "                if link and not link.startswith('http') and link.startswith('/'):\n",
        "                    link = 'https://www.abpananda.com' + link\n",
        "\n",
        "                if title and len(title) > 20 and 'abpananda.com' in link:\n",
        "                    headlines.append({\n",
        "                        'title': title,\n",
        "                        'link': link,\n",
        "                        'source': 'ABP Ananda',\n",
        "                        'published': 'Recent'\n",
        "                    })\n",
        "\n",
        "                if len(headlines) >= 15:\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error: {str(e)}\")\n",
        "\n",
        "        return headlines\n",
        "\n",
        "    def scrape_zee24ghanta(self, url):\n",
        "        \"\"\"Scrape Zee 24 Ghanta\"\"\"\n",
        "        headlines = []\n",
        "        try:\n",
        "            response = requests.get(url, headers=self.headers, timeout=10)\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            articles = soup.find_all('a', href=True)\n",
        "            for article in articles:\n",
        "                title = article.get_text(strip=True)\n",
        "                link = article.get('href', '')\n",
        "\n",
        "                if link and not link.startswith('http') and link.startswith('/'):\n",
        "                    link = 'https://zeenews.india.com' + link\n",
        "\n",
        "                if title and len(title) > 20 and 'bengali' in link:\n",
        "                    headlines.append({\n",
        "                        'title': title,\n",
        "                        'link': link,\n",
        "                        'source': 'Zee 24 Ghanta',\n",
        "                        'published': 'Recent'\n",
        "                    })\n",
        "\n",
        "                if len(headlines) >= 15:\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error: {str(e)}\")\n",
        "\n",
        "        return headlines\n",
        "\n",
        "    def scrape_news18_bengali(self, url):\n",
        "        \"\"\"Scrape News18 Bengali\"\"\"\n",
        "        headlines = []\n",
        "        try:\n",
        "            response = requests.get(url, headers=self.headers, timeout=10)\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            articles = soup.find_all(['h2', 'h3'])\n",
        "            for article in articles:\n",
        "                link_tag = article.find('a')\n",
        "                if link_tag:\n",
        "                    title = link_tag.get_text(strip=True)\n",
        "                    link = link_tag.get('href', '')\n",
        "\n",
        "                    if link and not link.startswith('http'):\n",
        "                        link = 'https://bengali.news18.com' + link\n",
        "\n",
        "                    if title and len(title) > 15:\n",
        "                        headlines.append({\n",
        "                            'title': title,\n",
        "                            'link': link,\n",
        "                            'source': 'News18 Bengali',\n",
        "                            'published': 'Recent'\n",
        "                        })\n",
        "\n",
        "                if len(headlines) >= 15:\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error: {str(e)}\")\n",
        "\n",
        "        return headlines\n",
        "\n",
        "    def scrape_telegraph(self, url):\n",
        "        \"\"\"Scrape The Telegraph\"\"\"\n",
        "        headlines = []\n",
        "        try:\n",
        "            response = requests.get(url, headers=self.headers, timeout=10)\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            articles = soup.find_all('a', href=True)\n",
        "            for article in articles:\n",
        "                title = article.get_text(strip=True)\n",
        "                link = article.get('href', '')\n",
        "\n",
        "                if (len(title) > 25 and\n",
        "                    link.startswith('/') and\n",
        "                    any(x in link.lower() for x in ['/bengal/', '/kolkata/', '/west-bengal/'])):\n",
        "\n",
        "                    link = 'https://www.telegraphindia.com' + link\n",
        "                    headlines.append({\n",
        "                        'title': title,\n",
        "                        'link': link,\n",
        "                        'source': 'The Telegraph Kolkata',\n",
        "                        'published': 'Recent'\n",
        "                    })\n",
        "\n",
        "                if len(headlines) >= 15:\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error: {str(e)}\")\n",
        "\n",
        "        return headlines\n",
        "\n",
        "    def scrape_bengal_live(self, url):\n",
        "        \"\"\"Scrape Bengal Live\"\"\"\n",
        "        headlines = []\n",
        "        try:\n",
        "            response = requests.get(url, headers=self.headers, timeout=10)\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            articles = soup.find_all(['h2', 'h3', 'h4'])\n",
        "            for article in articles:\n",
        "                link_tag = article.find('a')\n",
        "                if link_tag:\n",
        "                    title = link_tag.get_text(strip=True)\n",
        "                    link = link_tag.get('href', '')\n",
        "\n",
        "                    if link and not link.startswith('http'):\n",
        "                        link = 'https://bengallive.com' + link\n",
        "\n",
        "                    if title and len(title) > 15:\n",
        "                        headlines.append({\n",
        "                            'title': title,\n",
        "                            'link': link,\n",
        "                            'source': 'Bengal Live',\n",
        "                            'published': 'Recent'\n",
        "                        })\n",
        "\n",
        "                if len(headlines) >= 15:\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error: {str(e)}\")\n",
        "\n",
        "        return headlines\n",
        "\n",
        "    def scrape_bartaman(self, url):\n",
        "        \"\"\"Scrape Bartaman Patrika\"\"\"\n",
        "        headlines = []\n",
        "        try:\n",
        "            response = requests.get(url, headers=self.headers, timeout=10)\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            articles = soup.find_all('a', href=True)\n",
        "            for article in articles:\n",
        "                title = article.get_text(strip=True)\n",
        "                link = article.get('href', '')\n",
        "\n",
        "                if link and not link.startswith('http') and link.startswith('/'):\n",
        "                    link = 'https://bartamanpatrika.com' + link\n",
        "\n",
        "                if title and len(title) > 20 and 'bartamanpatrika.com' in link:\n",
        "                    headlines.append({\n",
        "                        'title': title,\n",
        "                        'link': link,\n",
        "                        'source': 'Bartaman Patrika',\n",
        "                        'published': 'Recent'\n",
        "                    })\n",
        "\n",
        "                if len(headlines) >= 15:\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error: {str(e)}\")\n",
        "\n",
        "        return headlines\n",
        "\n",
        "    def fetch_all_news(self):\n",
        "        \"\"\"Fetch news from all available sources\"\"\"\n",
        "        all_headlines = []\n",
        "\n",
        "        print(\"=\" * 70)\n",
        "        print(\" \" * 15 + \"MULTI-SOURCE NEWS AGGREGATION\")\n",
        "        print(\"=\" * 70)\n",
        "        print()\n",
        "\n",
        "        # Fetch from RSS feeds\n",
        "        print(\"üì° Fetching from RSS Feeds...\")\n",
        "        print(\"-\" * 70)\n",
        "        for source_name, url in self.rss_sources.items():\n",
        "            headlines = self.fetch_rss_feed(url, source_name)\n",
        "            all_headlines.extend(headlines)\n",
        "            time.sleep(0.5)  # Be polite\n",
        "\n",
        "        print()\n",
        "        print(\"üåê Attempting to scrape additional sources...\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        # Try scraping sources\n",
        "        for source in self.scraping_sources:\n",
        "            try:\n",
        "                print(f\"Attempting to scrape {source['name']}...\")\n",
        "                scraped_headlines = source['method'](source['url'])\n",
        "                if scraped_headlines:\n",
        "                    all_headlines.extend(scraped_headlines)\n",
        "                    print(f\"  ‚úì Found {len(scraped_headlines)} headlines from {source['name']}\")\n",
        "                else:\n",
        "                    print(f\"  ‚úó No headlines found from {source['name']}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚úó Could not scrape {source['name']}: {str(e)}\")\n",
        "\n",
        "            time.sleep(1)  # Be polite between requests\n",
        "\n",
        "        print()\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"Total headlines collected: {len(all_headlines)}\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Remove duplicates\n",
        "        seen_titles = set()\n",
        "        unique_headlines = []\n",
        "        for headline in all_headlines:\n",
        "            title_lower = headline['title'].lower().strip()\n",
        "            if title_lower not in seen_titles and len(title_lower) > 10:\n",
        "                seen_titles.add(title_lower)\n",
        "                unique_headlines.append(headline)\n",
        "\n",
        "        print(f\"Unique headlines after deduplication: {len(unique_headlines)}\")\n",
        "        print()\n",
        "\n",
        "        return unique_headlines\n",
        "\n",
        "def generate_html(headlines):\n",
        "    \"\"\"Generate beautiful HTML page with all news headlines\"\"\"\n",
        "\n",
        "    # Group headlines by source\n",
        "    grouped_headlines = {}\n",
        "    for headline in headlines:\n",
        "        source = headline['source']\n",
        "        if source not in grouped_headlines:\n",
        "            grouped_headlines[source] = []\n",
        "        grouped_headlines[source].append(headline)\n",
        "\n",
        "    html_content = f\"\"\"\n",
        "    <!DOCTYPE html>\n",
        "    <html lang=\"en\">\n",
        "    <head>\n",
        "        <meta charset=\"UTF-8\">\n",
        "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "        <title>Multi-Source News Aggregator - Latest Headlines</title>\n",
        "        <style>\n",
        "            * {{\n",
        "                margin: 0;\n",
        "                padding: 0;\n",
        "                box-sizing: border-box;\n",
        "            }}\n",
        "\n",
        "            body {{\n",
        "                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                min-height: 100vh;\n",
        "                padding: 20px;\n",
        "            }}\n",
        "\n",
        "            .container {{\n",
        "                max-width: 1400px;\n",
        "                margin: 0 auto;\n",
        "                background: white;\n",
        "                border-radius: 15px;\n",
        "                box-shadow: 0 20px 60px rgba(0,0,0,0.3);\n",
        "                overflow: hidden;\n",
        "            }}\n",
        "\n",
        "            .header {{\n",
        "                background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);\n",
        "                color: white;\n",
        "                padding: 40px 30px;\n",
        "                text-align: center;\n",
        "            }}\n",
        "\n",
        "            .header h1 {{\n",
        "                font-size: 2.8em;\n",
        "                margin-bottom: 10px;\n",
        "                text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\n",
        "            }}\n",
        "\n",
        "            .header p {{\n",
        "                font-size: 1.2em;\n",
        "                opacity: 0.95;\n",
        "            }}\n",
        "\n",
        "            .stats {{\n",
        "                display: flex;\n",
        "                justify-content: space-around;\n",
        "                background: #f8f9fa;\n",
        "                padding: 20px;\n",
        "                border-bottom: 2px solid #e9ecef;\n",
        "                flex-wrap: wrap;\n",
        "                gap: 15px;\n",
        "            }}\n",
        "\n",
        "            .stat-item {{\n",
        "                text-align: center;\n",
        "                min-width: 120px;\n",
        "            }}\n",
        "\n",
        "            .stat-number {{\n",
        "                font-size: 2em;\n",
        "                font-weight: bold;\n",
        "                color: #667eea;\n",
        "            }}\n",
        "\n",
        "            .stat-label {{\n",
        "                font-size: 0.9em;\n",
        "                color: #666;\n",
        "                margin-top: 5px;\n",
        "            }}\n",
        "\n",
        "            .timestamp {{\n",
        "                background: #fff3cd;\n",
        "                padding: 15px;\n",
        "                text-align: center;\n",
        "                color: #856404;\n",
        "                font-size: 0.95em;\n",
        "                border-bottom: 2px solid #ffc107;\n",
        "            }}\n",
        "\n",
        "            .filters {{\n",
        "                padding: 20px 30px;\n",
        "                background: #f8f9fa;\n",
        "                border-bottom: 1px solid #dee2e6;\n",
        "            }}\n",
        "\n",
        "            .filter-search {{\n",
        "                margin-bottom: 15px;\n",
        "            }}\n",
        "\n",
        "            .filter-search input {{\n",
        "                width: 100%;\n",
        "                padding: 12px 20px;\n",
        "                border: 2px solid #667eea;\n",
        "                border-radius: 25px;\n",
        "                font-size: 1em;\n",
        "                outline: none;\n",
        "                transition: all 0.3s ease;\n",
        "            }}\n",
        "\n",
        "            .filter-search input:focus {{\n",
        "                box-shadow: 0 0 10px rgba(102, 126, 234, 0.3);\n",
        "            }}\n",
        "\n",
        "            .filter-buttons {{\n",
        "                display: flex;\n",
        "                flex-wrap: wrap;\n",
        "                gap: 10px;\n",
        "                max-height: 200px;\n",
        "                overflow-y: auto;\n",
        "            }}\n",
        "\n",
        "            .filter-btn {{\n",
        "                padding: 8px 16px;\n",
        "                border: 2px solid #667eea;\n",
        "                background: white;\n",
        "                color: #667eea;\n",
        "                border-radius: 20px;\n",
        "                cursor: pointer;\n",
        "                transition: all 0.3s ease;\n",
        "                font-size: 0.85em;\n",
        "                white-space: nowrap;\n",
        "            }}\n",
        "\n",
        "            .filter-btn:hover {{\n",
        "                background: #667eea;\n",
        "                color: white;\n",
        "            }}\n",
        "\n",
        "            .filter-btn.active {{\n",
        "                background: #667eea;\n",
        "                color: white;\n",
        "            }}\n",
        "\n",
        "            .content {{\n",
        "                padding: 30px;\n",
        "            }}\n",
        "\n",
        "            .source-section {{\n",
        "                margin-bottom: 40px;\n",
        "            }}\n",
        "\n",
        "            .source-header {{\n",
        "                display: flex;\n",
        "                align-items: center;\n",
        "                margin-bottom: 20px;\n",
        "                padding-bottom: 10px;\n",
        "                border-bottom: 3px solid #667eea;\n",
        "            }}\n",
        "\n",
        "            .source-icon {{\n",
        "                width: 40px;\n",
        "                height: 40px;\n",
        "                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                border-radius: 50%;\n",
        "                display: flex;\n",
        "                align-items: center;\n",
        "                justify-content: center;\n",
        "                color: white;\n",
        "                font-weight: bold;\n",
        "                margin-right: 15px;\n",
        "                font-size: 1.2em;\n",
        "            }}\n",
        "\n",
        "            .source-name {{\n",
        "                font-size: 1.4em;\n",
        "                font-weight: bold;\n",
        "                color: #2c3e50;\n",
        "            }}\n",
        "\n",
        "            .source-count {{\n",
        "                margin-left: auto;\n",
        "                background: #667eea;\n",
        "                color: white;\n",
        "                padding: 5px 15px;\n",
        "                border-radius: 20px;\n",
        "                font-size: 0.9em;\n",
        "            }}\n",
        "\n",
        "            .headlines-grid {{\n",
        "                display: grid;\n",
        "                grid-template-columns: repeat(auto-fill, minmax(320px, 1fr));\n",
        "                gap: 20px;\n",
        "            }}\n",
        "\n",
        "            .headline-card {{\n",
        "                background: white;\n",
        "                border: 2px solid #e9ecef;\n",
        "                border-radius: 10px;\n",
        "                padding: 20px;\n",
        "                transition: all 0.3s ease;\n",
        "                position: relative;\n",
        "                overflow: hidden;\n",
        "            }}\n",
        "\n",
        "            .headline-card::before {{\n",
        "                content: '';\n",
        "                position: absolute;\n",
        "                left: 0;\n",
        "                top: 0;\n",
        "                height: 100%;\n",
        "                width: 4px;\n",
        "                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                transform: scaleY(0);\n",
        "                transition: transform 0.3s ease;\n",
        "            }}\n",
        "\n",
        "            .headline-card:hover {{\n",
        "                border-color: #667eea;\n",
        "                box-shadow: 0 5px 20px rgba(102, 126, 234, 0.2);\n",
        "                transform: translateY(-3px);\n",
        "            }}\n",
        "\n",
        "            .headline-card:hover::before {{\n",
        "                transform: scaleY(1);\n",
        "            }}\n",
        "\n",
        "            .headline-card a {{\n",
        "                text-decoration: none;\n",
        "                color: #2c3e50;\n",
        "                display: block;\n",
        "            }}\n",
        "\n",
        "            .headline-title {{\n",
        "                font-size: 1.05em;\n",
        "                line-height: 1.6;\n",
        "                margin-bottom: 10px;\n",
        "                font-weight: 500;\n",
        "            }}\n",
        "\n",
        "            .headline-card:hover .headline-title {{\n",
        "                color: #667eea;\n",
        "            }}\n",
        "\n",
        "            .headline-meta {{\n",
        "                display: flex;\n",
        "                justify-content: space-between;\n",
        "                align-items: center;\n",
        "                font-size: 0.85em;\n",
        "                color: #6c757d;\n",
        "                margin-top: 10px;\n",
        "                padding-top: 10px;\n",
        "                border-top: 1px solid #e9ecef;\n",
        "            }}\n",
        "\n",
        "            .published-date {{\n",
        "                font-style: italic;\n",
        "            }}\n",
        "\n",
        "            .read-more {{\n",
        "                color: #667eea;\n",
        "                font-weight: 600;\n",
        "            }}\n",
        "\n",
        "            .no-headlines {{\n",
        "                text-align: center;\n",
        "                padding: 60px 20px;\n",
        "                color: #666;\n",
        "            }}\n",
        "\n",
        "            .no-headlines-icon {{\n",
        "                font-size: 4em;\n",
        "                margin-bottom: 20px;\n",
        "            }}\n",
        "\n",
        "            .footer {{\n",
        "                background: #2c3e50;\n",
        "                color: white;\n",
        "                padding: 30px;\n",
        "                text-align: center;\n",
        "            }}\n",
        "\n",
        "            .footer-links {{\n",
        "                margin-top: 15px;\n",
        "            }}\n",
        "\n",
        "            .footer-link {{\n",
        "                color: #667eea;\n",
        "                text-decoration: none;\n",
        "                margin: 0 10px;\n",
        "            }}\n",
        "\n",
        "            .footer-link:hover {{\n",
        "                text-decoration: underline;\n",
        "            }}\n",
        "\n",
        "            .source-list {{\n",
        "                margin-top: 20px;\n",
        "                font-size: 0.85em;\n",
        "                opacity: 0.8;\n",
        "                line-height: 1.8;\n",
        "            }}\n",
        "\n",
        "            @media (max-width: 768px) {{\n",
        "                .headlines-grid {{\n",
        "                    grid-template-columns: 1fr;\n",
        "                }}\n",
        "\n",
        "                .stats {{\n",
        "                    flex-direction: column;\n",
        "                }}\n",
        "\n",
        "                .header h1 {{\n",
        "                    font-size: 2em;\n",
        "                }}\n",
        "\n",
        "                .filter-buttons {{\n",
        "                    max-height: 150px;\n",
        "                }}\n",
        "            }}\n",
        "        </style>\n",
        "    </head>\n",
        "    <body>\n",
        "        <div class=\"container\">\n",
        "            <div class=\"header\">\n",
        "                <h1>üì∞ Multi-Source News by Mr Bukkan</h1>\n",
        "                <p>Latest Headlines from {len(grouped_headlines)} Different Sources</p>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"stats\">\n",
        "                <div class=\"stat-item\">\n",
        "                    <div class=\"stat-number\">{len(headlines)}</div>\n",
        "                    <div class=\"stat-label\">Total Headlines</div>\n",
        "                </div>\n",
        "                <div class=\"stat-item\">\n",
        "                    <div class=\"stat-number\">{len(grouped_headlines)}</div>\n",
        "                    <div class=\"stat-label\">News Sources</div>\n",
        "                </div>\n",
        "                <div class=\"stat-item\">\n",
        "                    <div class=\"stat-number\">Live</div>\n",
        "                    <div class=\"stat-label\">Status</div>\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"timestamp\">\n",
        "                <strong>üïê Last Updated:</strong> {datetime.now().strftime('%B %d, %Y at %I:%M %p IST')}\n",
        "            </div>\n",
        "\n",
        "            <div class=\"filters\">\n",
        "                <div class=\"filter-search\">\n",
        "                    <input type=\"text\" id=\"searchBox\" placeholder=\"üîç Search headlines...\" onkeyup=\"searchHeadlines()\">\n",
        "                </div>\n",
        "                <div class=\"filter-buttons\">\n",
        "                    <button class=\"filter-btn active\" onclick=\"filterSource('all')\">All Sources ({len(headlines)})</button>\n",
        "    \"\"\"\n",
        "\n",
        "    for source in sorted(grouped_headlines.keys()):\n",
        "        html_content += f\"\"\"\n",
        "                    <button class=\"filter-btn\" onclick=\"filterSource('{source}')\">{source} ({len(grouped_headlines[source])})</button>\n",
        "        \"\"\"\n",
        "\n",
        "    html_content += \"\"\"\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"content\" id=\"newsContent\">\n",
        "    \"\"\"\n",
        "\n",
        "    if headlines:\n",
        "        for source in sorted(grouped_headlines.keys()):\n",
        "            source_headlines = grouped_headlines[source]\n",
        "            html_content += f\"\"\"\n",
        "                <div class=\"source-section\" data-source=\"{source}\">\n",
        "                    <div class=\"source-header\">\n",
        "                        <div class=\"source-icon\">{source[0]}</div>\n",
        "                        <div class=\"source-name\">{source}</div>\n",
        "                        <div class=\"source-count\">{len(source_headlines)} articles</div>\n",
        "                    </div>\n",
        "\n",
        "                    <div class=\"headlines-grid\">\n",
        "            \"\"\"\n",
        "\n",
        "            for headline in source_headlines:\n",
        "                published = headline.get('published', 'N/A')\n",
        "                if len(published) > 50:\n",
        "                    published = published[:50] + '...'\n",
        "\n",
        "                html_content += f\"\"\"\n",
        "                        <div class=\"headline-card\">\n",
        "                            <a href=\"{headline['link']}\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
        "                                <div class=\"headline-title\">{headline['title']}</div>\n",
        "                                <div class=\"headline-meta\">\n",
        "                                    <span class=\"published-date\">{published}</span>\n",
        "                                    <span class=\"read-more\">Read more ‚Üí</span>\n",
        "                                </div>\n",
        "                            </a>\n",
        "                        </div>\n",
        "                \"\"\"\n",
        "\n",
        "            html_content += \"\"\"\n",
        "                    </div>\n",
        "                </div>\n",
        "            \"\"\"\n",
        "    else:\n",
        "        html_content += \"\"\"\n",
        "                <div class=\"no-headlines\">\n",
        "                    <div class=\"no-headlines-icon\">üì≠</div>\n",
        "                    <h2>No Headlines Available</h2>\n",
        "                    <p>Please check back later or try refreshing the page.</p>\n",
        "                </div>\n",
        "        \"\"\"\n",
        "\n",
        "    html_content += \"\"\"\n",
        "            </div>\n",
        "\n",
        "            <div class=\"footer\">\n",
        "                <p><strong>Multi-Source News by bukkan1309@gmail.com </strong></p>\n",
        "                <p>Aggregating news from 30+ RSS feeds and web sources</p>\n",
        "                <div class=\"source-list\">\n",
        "                    <strong>Sources Include:</strong> Google News, The Telegraph, The Hindu, Times of India, Indian Express,\n",
        "                    NDTV, India Today, Hindustan Times, Economic Times, Business Standard, Mint, Ei Samay,\n",
        "                    Sangbad Pratidin, ABP Ananda, Zee 24 Ghanta, News18 Bengali, Bengal Live, Bartaman Patrika and more\n",
        "                </div>\n",
        "                <div class=\"footer-links\">\n",
        "                    <a href=\"#\" class=\"footer-link\">About</a>\n",
        "                    <a href=\"#\" class=\"footer-link\">Privacy</a>\n",
        "                    <a href=\"#\" class=\"footer-link\">Sources</a>\n",
        "                </div>\n",
        "                <p style=\"margin-top: 15px; font-size: 0.85em; opacity: 0.8;\">\n",
        "                    All news content belongs to respective publishers\n",
        "                </p>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <script>\n",
        "            function filterSource(source) {\n",
        "                const sections = document.querySelectorAll('.source-section');\n",
        "                const buttons = document.querySelectorAll('.filter-btn');\n",
        "\n",
        "                buttons.forEach(btn => btn.classList.remove('active'));\n",
        "                event.target.classList.add('active');\n",
        "\n",
        "                // Clear search when filtering\n",
        "                document.getElementById('searchBox').value = '';\n",
        "\n",
        "                if (source === 'all') {\n",
        "                    sections.forEach(section => section.style.display = 'block');\n",
        "                } else {\n",
        "                    sections.forEach(section => {\n",
        "                        if (section.dataset.source === source) {\n",
        "                            section.style.display = 'block';\n",
        "                        } else {\n",
        "                            section.style.display = 'none';\n",
        "                        }\n",
        "                    });\n",
        "                }\n",
        "            }\n",
        "\n",
        "            function searchHeadlines() {\n",
        "                const searchTerm = document.getElementById('searchBox').value.toLowerCase();\n",
        "                const sections = document.querySelectorAll('.source-section');\n",
        "\n",
        "                // Reset filter buttons\n",
        "                const buttons = document.querySelectorAll('.filter-btn');\n",
        "                buttons.forEach(btn => btn.classList.remove('active'));\n",
        "\n",
        "                if (searchTerm === '') {\n",
        "                    // Show all if search is empty\n",
        "                    sections.forEach(section => {\n",
        "                        section.style.display = 'block';\n",
        "                        const cards = section.querySelectorAll('.headline-card');\n",
        "                        cards.forEach(card => card.style.display = 'block');\n",
        "                    });\n",
        "                    document.querySelector('.filter-btn').classList.add('active');\n",
        "                    return;\n",
        "                }\n",
        "\n",
        "                sections.forEach(section => {\n",
        "                    const cards = section.querySelectorAll('.headline-card');\n",
        "                    let hasVisibleCard = false;\n",
        "\n",
        "                    cards.forEach(card => {\n",
        "                        const title = card.querySelector('.headline-title').textContent.toLowerCase();\n",
        "                        if (title.includes(searchTerm)) {\n",
        "                            card.style.display = 'block';\n",
        "                            hasVisibleCard = true;\n",
        "                        } else {\n",
        "                            card.style.display = 'none';\n",
        "                        }\n",
        "                    });\n",
        "\n",
        "                    // Show/hide section based on whether it has visible cards\n",
        "                    section.style.display = hasVisibleCard ? 'block' : 'none';\n",
        "                });\n",
        "            }\n",
        "\n",
        "            // Add smooth scroll to top button\n",
        "            window.onscroll = function() {\n",
        "                if (document.body.scrollTop > 300 || document.documentElement.scrollTop > 300) {\n",
        "                    if (!document.getElementById('scrollTopBtn')) {\n",
        "                        const btn = document.createElement('button');\n",
        "                        btn.id = 'scrollTopBtn';\n",
        "                        btn.innerHTML = '‚Üë';\n",
        "                        btn.style.cssText = `\n",
        "                            position: fixed;\n",
        "                            bottom: 30px;\n",
        "                            right: 30px;\n",
        "                            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                            color: white;\n",
        "                            border: none;\n",
        "                            border-radius: 50%;\n",
        "                            width: 50px;\n",
        "                            height: 50px;\n",
        "                            font-size: 24px;\n",
        "                            cursor: pointer;\n",
        "                            box-shadow: 0 5px 15px rgba(0,0,0,0.3);\n",
        "                            z-index: 1000;\n",
        "                            transition: all 0.3s ease;\n",
        "                        `;\n",
        "                        btn.onclick = function() {\n",
        "                            window.scrollTo({ top: 0, behavior: 'smooth' });\n",
        "                        };\n",
        "                        btn.onmouseover = function() {\n",
        "                            this.style.transform = 'scale(1.1)';\n",
        "                        };\n",
        "                        btn.onmouseout = function() {\n",
        "                            this.style.transform = 'scale(1)';\n",
        "                        };\n",
        "                        document.body.appendChild(btn);\n",
        "                    }\n",
        "                } else {\n",
        "                    const btn = document.getElementById('scrollTopBtn');\n",
        "                    if (btn) btn.remove();\n",
        "                }\n",
        "            };\n",
        "        </script>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "    return html_content\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the news aggregator\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\" \" * 10 + \"MULTI-SOURCE NEWS AGGREGATOR\")\n",
        "    print(\" \" * 15 + \"Powered by 30+ Sources\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    # Create aggregator instance\n",
        "    aggregator = BengaliNewsAggregator()\n",
        "\n",
        "    # Fetch all news\n",
        "    headlines = aggregator.fetch_all_news()\n",
        "\n",
        "    if headlines:\n",
        "        # Generate HTML\n",
        "        print(\"Generating HTML page...\")\n",
        "        html_content = generate_html(headlines)\n",
        "\n",
        "        # Save to file\n",
        "        output_file = 'multi_source_news_aggregator.html'\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(html_content)\n",
        "\n",
        "        print(f\"\\n‚úì Success! HTML file generated: {output_file}\")\n",
        "        print(f\"‚úì Total unique headlines: {len(headlines)}\")\n",
        "\n",
        "        # Show source breakdown\n",
        "        sources = {}\n",
        "        for headline in headlines:\n",
        "            source = headline['source']\n",
        "            sources[source] = sources.get(source, 0) + 1\n",
        "\n",
        "        print(f\"\\nüìä Headlines by Source:\")\n",
        "        print(\"-\" * 70)\n",
        "        for source, count in sorted(sources.items(), key=lambda x: x[1], reverse=True):\n",
        "            print(f\"  {source}: {count} headlines\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\" \" * 10 + \"Open the HTML file in your browser!\")\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "    else:\n",
        "        print(\"\\n‚úó No headlines were collected. Please check your internet connection.\")\n",
        "        print(\"  or the availability of news sources.\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v64FVGF89RT_",
        "outputId": "f2d4bbd6-a17d-45ea-f992-224614d8b1ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Collecting sgmllib3k (from feedparser)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=7c4e07b589190004600602246ec0c88839aa55bd29b9f33cd0109e8ce09ddbb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser\n",
            "Successfully installed feedparser-6.0.12 sgmllib3k-1.0.0\n",
            "\n",
            "======================================================================\n",
            "          MULTI-SOURCE NEWS AGGREGATOR\n",
            "               Powered by 30+ Sources\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "               MULTI-SOURCE NEWS AGGREGATION\n",
            "======================================================================\n",
            "\n",
            "üì° Fetching from RSS Feeds...\n",
            "----------------------------------------------------------------------\n",
            "Fetching from Google News - Bengal...\n",
            "  ‚úì Found 20 headlines from Google News - Bengal\n",
            "Fetching from Google News - India (Bengali)...\n",
            "  ‚úì Found 20 headlines from Google News - India (Bengali)\n",
            "Fetching from Google News - West Bengal...\n",
            "  ‚úì Found 20 headlines from Google News - West Bengal\n",
            "Fetching from The Telegraph Bengal...\n",
            "  Warning: Feed parsing issue for The Telegraph Bengal\n",
            "  ‚úì Found 0 headlines from The Telegraph Bengal\n",
            "Fetching from The Hindu - West Bengal...\n",
            "  ‚úì Found 20 headlines from The Hindu - West Bengal\n",
            "Fetching from Times of India - Kolkata...\n",
            "  ‚úì Found 0 headlines from Times of India - Kolkata\n",
            "Fetching from Indian Express - Kolkata...\n",
            "  ‚úì Found 20 headlines from Indian Express - Kolkata\n",
            "Fetching from NDTV - Kolkata...\n",
            "  Warning: Feed parsing issue for NDTV - Kolkata\n",
            "  ‚úì Found 0 headlines from NDTV - Kolkata\n",
            "Fetching from The Hindu - National...\n",
            "  ‚úì Found 20 headlines from The Hindu - National\n",
            "Fetching from Times of India - India...\n",
            "  ‚úì Found 20 headlines from Times of India - India\n",
            "Fetching from India Today...\n",
            "  Warning: Feed parsing issue for India Today\n",
            "  ‚úì Found 20 headlines from India Today\n",
            "Fetching from NDTV News...\n",
            "  ‚úì Found 20 headlines from NDTV News\n",
            "Fetching from Hindustan Times...\n",
            "  ‚úì Found 20 headlines from Hindustan Times\n",
            "Fetching from The Indian Express...\n",
            "  ‚úì Found 20 headlines from The Indian Express\n",
            "Fetching from Economic Times...\n",
            "  ‚úì Found 20 headlines from Economic Times\n",
            "Fetching from Business Standard...\n",
            "  Warning: Feed parsing issue for Business Standard\n",
            "  ‚úì Found 0 headlines from Business Standard\n",
            "Fetching from Mint...\n",
            "  ‚úì Found 20 headlines from Mint\n",
            "Fetching from Sports - Times of India...\n",
            "  ‚úì Found 20 headlines from Sports - Times of India\n",
            "Fetching from Cricket News...\n",
            "  ‚úì Found 20 headlines from Cricket News\n",
            "Fetching from Tech News India...\n",
            "  ‚úì Found 20 headlines from Tech News India\n",
            "\n",
            "üåê Attempting to scrape additional sources...\n",
            "----------------------------------------------------------------------\n",
            "Attempting to scrape Ei Samay...\n",
            "  ‚úó No headlines found from Ei Samay\n",
            "Attempting to scrape Sangbad Pratidin...\n",
            "  ‚úó No headlines found from Sangbad Pratidin\n",
            "Attempting to scrape ABP Ananda...\n",
            "  ‚úì Found 2 headlines from ABP Ananda\n",
            "Attempting to scrape Zee 24 Ghanta...\n",
            "  ‚úì Found 15 headlines from Zee 24 Ghanta\n",
            "Attempting to scrape News18 Bengali...\n",
            "  ‚úó No headlines found from News18 Bengali\n",
            "Attempting to scrape The Telegraph Kolkata...\n",
            "  ‚úó No headlines found from The Telegraph Kolkata\n",
            "Attempting to scrape Bengal Live...\n",
            "    Error: HTTPSConnectionPool(host='bengallive.com', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x78ec2a9a5880>: Failed to resolve 'bengallive.com' ([Errno -2] Name or service not known)\"))\n",
            "  ‚úó No headlines found from Bengal Live\n",
            "Attempting to scrape Bartaman Patrika...\n",
            "  ‚úì Found 15 headlines from Bartaman Patrika\n",
            "\n",
            "======================================================================\n",
            "Total headlines collected: 352\n",
            "======================================================================\n",
            "Unique headlines after deduplication: 347\n",
            "\n",
            "Generating HTML page...\n",
            "\n",
            "‚úì Success! HTML file generated: multi_source_news_aggregator.html\n",
            "‚úì Total unique headlines: 347\n",
            "\n",
            "üìä Headlines by Source:\n",
            "----------------------------------------------------------------------\n",
            "  Google News - India (Bengali): 20 headlines\n",
            "  Google News - West Bengal: 20 headlines\n",
            "  The Hindu - West Bengal: 20 headlines\n",
            "  Indian Express - Kolkata: 20 headlines\n",
            "  Times of India - India: 20 headlines\n",
            "  NDTV News: 20 headlines\n",
            "  Hindustan Times: 20 headlines\n",
            "  The Indian Express: 20 headlines\n",
            "  Economic Times: 20 headlines\n",
            "  Mint: 20 headlines\n",
            "  Sports - Times of India: 20 headlines\n",
            "  Cricket News: 20 headlines\n",
            "  Tech News India: 20 headlines\n",
            "  Google News - Bengal: 19 headlines\n",
            "  The Hindu - National: 18 headlines\n",
            "  India Today: 18 headlines\n",
            "  Zee 24 Ghanta: 15 headlines\n",
            "  Bartaman Patrika: 15 headlines\n",
            "  ABP Ananda: 2 headlines\n",
            "\n",
            "======================================================================\n",
            "          Open the HTML file in your browser!\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}