{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHy2nLjzymIOxyT3nvYEn2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sumant-crty/Python-Data-Scraping-Portfolio/blob/main/Newsbroadcast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x0UWCHeA44tD",
        "outputId": "f8b40def-e286-49b9-ad54-c133a289ff2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting newspaper3k\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting lxml_html_clean\n",
            "  Downloading lxml_html_clean-0.4.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (4.13.5)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (11.3.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.3)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
            "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.2)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (3.9.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.32.4)\n",
            "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
            "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting tldextract>=2.0.1 (from newspaper3k)\n",
            "  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.9.0.post0)\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (4.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n",
            "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2025.11.12)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
            "  Downloading requests_file-3.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.20.0)\n",
            "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml_html_clean-0.4.3-py3-none-any.whl (14 kB)\n",
            "Downloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
            "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-3.0.1-py2.py3-none-any.whl (4.5 kB)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13540 sha256=dc8c3eeab3a2604614bb0c602505f8102861bb75e54dacc2c4cb27de8bff73e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/91/9f/00d66475960891a64867914273fcaf78df6cb04d905b104a2a\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3341 sha256=42dd5e1a5c9f0a30342d6b81484d016ad1714dfbf4622e734558db402a5700b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/9f/fb/364871d7426d3cdd4d293dcf7e53d97f160c508b2ccf00cc79\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398380 sha256=4771adfbff472140bfd51e27377730f26ad74970384607ecee7720b392ceae56\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/72/f7/fff392a8d4ea988dea4ccf9788599d09462a7f5e51e04f8a92\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=8a8e6506026cec597da52aa66d7b4cc5cfaea7b11c888cb01ceed58d0dbdc480\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, lxml_html_clean, feedparser, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n",
            "Successfully installed cssselect-1.3.0 feedfinder2-0.0.4 feedparser-6.0.12 jieba3k-0.35.1 lxml_html_clean-0.4.3 newspaper3k-0.2.8 requests-file-3.0.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>Latest News Headlines - 28-12-2025</h1>\n",
              "<ul>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/entertainment/hindi/bollywood/news/mannara-chopra-says-her-bond-with-priyanka-chopra-has-internally-changed-calls-malti-marie-a-proper-la-baby-she-is-like-that-calming-factor/articleshow/126193441.cms\" target=\"_blank\">Mannara Chopra says her bond with Priyanka Chopra has ‘internally changed’; calls Malti Marie ‘a proper LA baby’, ‘She is like that calming factor’</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/sports/nfl/news/nfl-off-field-controversies-that-made-headlines-in-2025-legal-drama-social-media-storms-and-public-fallout/articleshow/126213508.cms\" target=\"_blank\">NFL off-field controversies that made headlines in 2025: Legal drama, social media storms, and public fallout</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/entertainment/hindi/bollywood/news/drishyam-3-row-producer-calls-jaideep-alhawat-a-better-actor-and-person-than-akshaye-khanna/articleshow/126212446.cms\" target=\"_blank\">‘Drishyam 3’ row: Producer calls Jaideep Alhawat a ‘BETTER’ actor and person than Akshaye Khanna</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/business/silver-rates-today\" target=\"_blank\">Check Out Silver Price Per Gram & Per Kg in India</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/sports/nfl/news/robert-kraft-vs-gayle-benson-net-worth-how-do-their-finances-compare/articleshow/126186763.cms\" target=\"_blank\">Robert Kraft vs. Gayle Benson net worth: How do their finances compare?</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/life-style/beauty/why-these-five-anti-ageing-drinks-have-become-our-quiet-wellness-ritual/articleshow/126204465.cms\" target=\"_blank\">Why these five anti-ageing drinks have become our quiet wellness ritual</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/feedback.cms\" target=\"_blank\">The Times of India</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/sports/formula-one/news/toto-wolff-and-susie-wolff-combined-net-worth-in-2025-formula-1-leadership-investments-ownership-stakes-and-lifestyle/articleshow/126190577.cms\" target=\"_blank\">Toto Wolff and Susie Wolff combined net worth in 2025: Formula 1 leadership, investments, ownership stakes, and lifestyle</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/world/us/decoded-barron-trumps-troubling-relationship-with-andrew-tate-and-the-misogynist-manosphere/articleshow/126213354.cms\" target=\"_blank\">Decoded: Barron Trump's troubling relationship with Andrew Tate and the misogynist 'manosphere'</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/life-style/relationships\" target=\"_blank\">Relationship, Man Woman Relationship Advice, Parenting Advice & Dating Tips</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/news/national/west-bengal/\" target=\"_blank\">West Bengal news, Latest and Live Updates on Weather news, Politics, Events</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/opinion/\" target=\"_blank\">Opinions</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/business/budget/\" target=\"_blank\">Budget 2025: Latest news, budget highlights and expectations for FY 2025-26</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/business/Economy/what-are-the-signals-from-the-indian-economy-explained/article70443208.ece\" target=\"_blank\">What are the signals from the Indian economy? | Explained</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/news/cities/Mangalore/\" target=\"_blank\">Mangalore - Latest News, Politics, Events, Entertainment</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/news/national/tamil-nadu/more-than-442-lakh-apply-for-inclusion-in-electoral-rolls-as-of-december-27-in-tamil-nadu/article70446157.ece\" target=\"_blank\">More than 4.42 lakh apply for inclusion in electoral rolls as of December 27 in Tamil Nadu</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/food/dining/\" target=\"_blank\">Discover the best restaurants in India | The Hindu’s Top Picks</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/food/guides/\" target=\"_blank\">Cooking Guide: Recipes, Techniques, and Brilliant Ideas</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/news/cities/Vijayawada/\" target=\"_blank\">Vijayawada - Latest News, Politics, Events, Entertainment</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/education/colleges/\" target=\"_blank\">Arts & Science, Engineering, Medical</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/db-original/news/du-ma-student-viral-video-fact-check-chitra-singh-instagram-fake-claim-police-investigation-136774513.html\" target=\"_blank\">प्रोफेसर पर रूम में बुलाने का आरोप, कहां गई DU-स्टूडेंट: 6 महीने में 2 क्लास, जांच कमेटी की रिपोर्ट से खुद सवालों में</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/local/rajasthan/alwar/news/alwar-experiences-freezing-cold-temperature-drops-by-one-degree-136793676.html\" target=\"_blank\">अलवर में सर्दी और तेज, एक डिग्री गिरा तापमान: 2 दिन शीतलहर चलने का अलर्ट, फसलों पर जमी ओस की बूंदें - Alwar News</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/local/uttar-pradesh/jhansi/news/11th-grade-student-commits-suicide-after-being-denied-an-iphone-136795699.html\" target=\"_blank\">iPhone के लिए 11वीं की छात्रा ने जान दी: झांसी में परिवार को दी थी धमकी; पिता बोला- गरीब हूं, कहां से लाता इतने रुपए - Jhansi News</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/?ref=inbound_RHS\" target=\"_blank\">Hindi News; Latest Hindi News, Breaking Hindi News Live, Hindi Samachar (हिंदी समाचार), Hindi News Paper Today</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/local/punjab/jalandhar/news/mahant-par-janleva-hamla-video-19-tareekh-aaropi-giraftari-nahi-136765851.html\" target=\"_blank\">जालंधर में महंत की पिटाई का VIDEO: ईंटे मारकर सिर फोड़ा, डंडों से पीट-पीटकर पैर तोड़ा; बधाई मांगने के इलाके को लेकर भिड़े - Jalandhar News</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/international/\" target=\"_blank\">International News in Hindi: अंतर्राष्ट्रीय समाचार, World News in Hindi, Videsh, विदेश</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/entertainment/bollywood/video/thalapathy-vijay-retirement-from-acting-after-33-years-focus-on-politics-last-film-jan-nayakan-136795988.html?type=widget&index=2&vid=13\" target=\"_blank\">nan</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/women/\" target=\"_blank\">Women issues Lifestyle beauty Tips in Hindi, Fashion & Lifestyle Updates, Fashion Trends</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/tech-auto/news/openai-fires-jobs-to-prevent-ai-threats-136793600.html\" target=\"_blank\">ओपनएआई ने AI के खतरे रोकने के लिए नौकरी निकाली: हेड ऑफ प्रिपयर्डनेस के पद पर हायरिंग; सैम ऑल्टमैन बोले- ये बेहद तनावपूर्ण नौकरी होगी</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/international/news/hadis-killers-fled-to-india-via-the-meghalaya-border-136795018.html\" target=\"_blank\">दावा- हादी के हत्यारे मेघालय बॉर्डर के रास्ते भारत भागे: बांग्लादेश पुलिस बोली- स्थानीय सहयोगियों की मदद से सीमा पार गए, जल्द हिरासत में लेंगे</a></li>\n",
              "</ul>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install newspaper3k lxml_html_clean\n",
        "\n",
        "# --- Import Libraries ---\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from newspaper import Article\n",
        "import csv\n",
        "import time\n",
        "import pandas as pd # Import pandas for DataFrame operations\n",
        "from datetime import datetime # Import datetime for current date\n",
        "from IPython.display import HTML # Import HTML for displaying web page content\n",
        "\n",
        "# --- Configuration ---\n",
        "BASE_URL = \"https://timesofindia.indiatimes.com/\"\n",
        "OUTPUT_FILENAME = \"toi_headlines.csv\"\n",
        "OUTPUT_ALL_HEADLINES_FILENAME = \"all_newspaper_headlines.csv\"\n",
        "HTML_OUTPUT_FILENAME = \"headlines.html\" # New: HTML output filename\n",
        "\n",
        "# CRUCIAL: Realistic User-Agent is necessary\n",
        "HEADERS = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "NEWSPAPER_CONFIGS = {\n",
        "    'Times of India': {'url': 'https://timesofindia.indiatimes.com/', 'language': 'en'},\n",
        "    'The Hindu': {'url': 'https://www.thehindu.com/', 'language': 'en'},\n",
        "    'Dainik Bhaskar': {'url': 'https://www.bhaskar.com/', 'language': 'hi'}\n",
        "}\n",
        "\n",
        "def get_article_links(url, base_url):\n",
        "    \"\"\"Downloads the page and returns a set of unique article links.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, headers=HEADERS, timeout=15)\n",
        "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        article_links = set()\n",
        "        excluded_keywords = [\n",
        "            'javascript:', '#', '.css', '.js', '.jpg', '.png', '.gif', '.pdf',\n",
        "            'videos', 'photos', 'gallery', 'e-paper', 'epaper', 'subscribe', 'newsletter',\n",
        "            'login', 'signin', 'register', 'terms-of-use', 'privacy-policy', 'contact-us', 'about-us',\n",
        "            'advertise', 'careers', 'sitemap', 'authors', 'topics', 'tags', 'archives'\n",
        "        ]\n",
        "\n",
        "        for a_tag in soup.find_all('a', href=True):\n",
        "            href = a_tag['href']\n",
        "            full_link = \"\"\n",
        "\n",
        "            # Construct full URL if relative\n",
        "            if href.startswith('http') and base_url.split('//')[1].split('/')[0] in href:\n",
        "                full_link = href\n",
        "            elif href.startswith('/') and not href.startswith('//'): # Relative URL\n",
        "                full_link = base_url.rstrip('/') + href\n",
        "\n",
        "            # Filter out obvious non-article links and duplicates\n",
        "            if full_link and not any(keyword in full_link for keyword in excluded_keywords):\n",
        "                if full_link != base_url and len(full_link) > len(base_url) + 5: # Avoid just base URL and very short links\n",
        "                    article_links.add(full_link)\n",
        "\n",
        "        return article_links # Moved outside the for loop\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"ERROR: Could not fetch {url}. Reason: {e}\")\n",
        "        return set()\n",
        "\n",
        "def scrape_article_data(links, language, limit=10):\n",
        "    \"\"\"Scrapes the title, date, and URL for each article link, up to a specified limit.\"\"\"\n",
        "    scraped_data = []\n",
        "    # Convert set to list and take only the first 'limit' items\n",
        "    links_to_process = list(links)[:limit]\n",
        "\n",
        "\n",
        "    for i, link in enumerate(links_to_process):\n",
        "\n",
        "\n",
        "        try:\n",
        "            # Use newspaper3k for intelligent article content extraction\n",
        "            article = Article(link, language=language)\n",
        "            article.download()\n",
        "            article.parse()\n",
        "\n",
        "            scraped_data.append({\n",
        "                \"Title\": article.title,\n",
        "                \"Publish_Date\": str(article.publish_date), # Convert datetime object to string\n",
        "                \"URL\": link\n",
        "            })\n",
        "\n",
        "            # Introduce a short, polite delay between requests\n",
        "            time.sleep(1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"WARNING: Failed to process article {link}. Skipping. Error: {e}\")\n",
        "            time.sleep(1) # Still pause if an error occurs\n",
        "            continue\n",
        "\n",
        "    return scraped_data\n",
        "\n",
        "def save_to_csv(data, filename):\n",
        "    \"\"\"Saves the list of dictionaries to a CSV file.\"\"\"\n",
        "    if not data:\n",
        "        print(\"No data to save.\")\n",
        "        return\n",
        "\n",
        "    # Use the keys of the first dictionary as the field names (headers)\n",
        "    fieldnames = data[0].keys()\n",
        "\n",
        "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        writer.writeheader() # Write the header row\n",
        "        writer.writerows(data) # Write all the data rows\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "if __name__ == \"__main__\":\n",
        "    all_scraped_data = []\n",
        "\n",
        "    for newspaper_name, config in NEWSPAPER_CONFIGS.items():\n",
        "        newspaper_url = config['url']\n",
        "        newspaper_language = config['language']\n",
        "\n",
        "            # 1. Get article links for the current newspaper\n",
        "        article_links = get_article_links(newspaper_url, newspaper_url)\n",
        "\n",
        "        if article_links:\n",
        "            # 2. Scrape article data for the current newspaper, with language and limit\n",
        "            newspaper_data = scrape_article_data(article_links, newspaper_language, limit=10)\n",
        "\n",
        "            # 3. Add 'Source' column to each article\n",
        "            for article in newspaper_data:\n",
        "                article['Source'] = newspaper_name\n",
        "\n",
        "            # 4. Accumulate all scraped data\n",
        "            all_scraped_data.extend(newspaper_data)\n",
        "        else:\n",
        "            print(f\"No article links found for {newspaper_name}.\")\n",
        "\n",
        "\n",
        "\n",
        "    # Save the combined results to a single CSV\n",
        "    save_to_csv(all_scraped_data, OUTPUT_ALL_HEADLINES_FILENAME)\n",
        "\n",
        "    # Load the combined data into a DataFrame\n",
        "    df_all_headlines = pd.read_csv(OUTPUT_ALL_HEADLINES_FILENAME)\n",
        "\n",
        "    # Display headlines in an HTML page with hyperlinks\n",
        "    current_date = datetime.now().strftime('%d-%m-%Y')\n",
        "\n",
        "    html_content_parts = [\n",
        "        f\"<h1>Latest News Headlines - {current_date}</h1>\\n\",\n",
        "        \"<ul>\\n\"\n",
        "    ]\n",
        "\n",
        "    for index, row in df_all_headlines.iterrows():\n",
        "        title = row['Title']\n",
        "        url = row['URL']\n",
        "        html_content_parts.append(f\"  <li><a href=\\\"{url}\\\" target=\\\"_blank\\\">{title}</a></li>\\n\")\n",
        "\n",
        "    html_content_parts.append(\"</ul>\")\n",
        "\n",
        "    new_html_content = \"\".join(html_content_parts)\n",
        "    display(HTML(new_html_content))\n",
        "\n",
        "    # New: Save the HTML content to a file\n",
        "    with open(HTML_OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n",
        "        f.write(new_html_content)"
      ]
    }
  ]
}