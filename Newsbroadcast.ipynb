{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOyvuROQhOB5HG8spGGseIG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sumant-crty/Python-Data-Scraping-Portfolio/blob/main/Newsbroadcast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x0UWCHeA44tD",
        "outputId": "f6d1d609-d877-4553-a197-5a48be667e59",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.12/dist-packages (0.2.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (4.13.5)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (11.3.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.3)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (1.3.0)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.2)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (3.9.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.32.4)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.12)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (5.3.0)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.9.0.post0)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (4.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.12/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2025.11.12)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.0.1)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.20.0)\n",
            "Collecting lxml_html_clean\n",
            "  Downloading lxml_html_clean-0.4.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from lxml_html_clean) (6.0.2)\n",
            "Downloading lxml_html_clean-0.4.3-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: lxml_html_clean\n",
            "Successfully installed lxml_html_clean-0.4.3\n",
            "\n",
            "=== Processing Times of India ===\n",
            "-> Collecting article links from: https://timesofindia.indiatimes.com/ using base URL: https://timesofindia.indiatimes.com/\n",
            "-> Found 386 unique potential article links.\n",
            "-> Scraping data for the first 10 articles...\n",
            "Scraping article 1/10: https://timesofindia.indiatimes.com/sports/nba/top-stories/fact-check-is-lebron-james-son-bronny-james-expecting-a-child-with-girlfriend-parker-whitfield-how-a-viral-hoax-dragged-the-los-angeles-lakers-rookie-into-speculation/articleshow/125951095.cms\n",
            "Scraping article 2/10: https://timesofindia.indiatimes.com/sports/more-sports/athletics/diamond-league-final-neeraj-chopras-event-preview-time-and-live-telecast-in-india/articleshow/123543024.cms\n",
            "Scraping article 3/10: https://timesofindia.indiatimes.com/business/platinum-rates-today\n",
            "Scraping article 4/10: https://timesofindia.indiatimes.com/sports/cricket/news/from-michael-clarke-to-yuvraj-singh-cricketers-who-battled-cancer-with-courage/articleshow/123544122.cms\n",
            "Scraping article 5/10: https://timesofindia.indiatimes.com/entertainment/english/hollywood/news/bondi-beach-attack-on-hanukkah-rebel-wilson-ashton-kutcher-gal-gadot-mandy-moore-and-other-hollywood-star-condemn-shooting/articleshow/125969547.cms\n",
            "Scraping article 6/10: https://timesofindia.indiatimes.com/tv/news/hindi/exclusive-shikha-singh-makes-a-comeback-after-6-years-with-jagadhatri-says-ive-always-been-inclined-towards-a-strong-character-over-anything-else/articleshow/125969030.cms\n",
            "Scraping article 7/10: https://timesofindia.indiatimes.com/travel\n",
            "Scraping article 8/10: https://timesofindia.indiatimes.com/city/thane\n",
            "Scraping article 9/10: https://timesofindia.indiatimes.com/world/rest-of-world/bondi-beach-mass-shooting-from-a-holocaust-survivor-to-a-10-yr-old-child-who-the-victims-were/articleshow/125969935.cms\n",
            "Scraping article 10/10: https://timesofindia.indiatimes.com/business/bank-holidays/is-bank-open-today\n",
            "\n",
            "=== Processing The Hindu ===\n",
            "-> Collecting article links from: https://www.thehindu.com/ using base URL: https://www.thehindu.com/\n",
            "-> Found 187 unique potential article links.\n",
            "-> Scraping data for the first 10 articles...\n",
            "Scraping article 1/10: https://www.thehindu.com/opinion/editorial/\n",
            "Scraping article 2/10: https://www.thehindu.com/topic/data-point-podcast/\n",
            "Scraping article 3/10: https://www.thehindu.com/news/international/bondi-beach-shooting-israeli-pm-netanyahu-warned-australian-counterpart-antisemitism/article70396205.ece\n",
            "Scraping article 4/10: https://www.thehindu.com/news/cities/Madurai/\n",
            "Scraping article 5/10: https://www.thehindu.com/sci-tech/technology/intel-has-tested-chipmaking-tools-from-firm-with-sanctioned-china-unit-sources-say/article70397673.ece\n",
            "Scraping article 6/10: https://www.thehindu.com/entertainment/music/umayalpuram-k-sivaraman-performing-where-he-did-his-debut/article70395627.ece\n",
            "Scraping article 7/10: https://www.thehindu.com/sci-tech/technology/why-are-nvidia-chips-being-sold-to-china-again-explained/article70393468.ece\n",
            "Scraping article 8/10: https://www.thehindu.com/opinion/lead/courts-must-protect-not-regulate-free-speech/article70396202.ece\n",
            "Scraping article 9/10: https://www.thehindu.com/specials/\n",
            "Scraping article 10/10: https://www.thehindu.com/life-and-style/motoring/\n",
            "\n",
            "=== Processing Dainik Bhaskar ===\n",
            "-> Collecting article links from: https://www.bhaskar.com/ using base URL: https://www.bhaskar.com/\n",
            "-> Found 152 unique potential article links.\n",
            "-> Scraping data for the first 10 articles...\n",
            "Scraping article 1/10: https://www.bhaskar.com/db-original/explainer/\n",
            "Scraping article 2/10: https://www.bhaskar.com/national/\n",
            "Scraping article 3/10: https://www.bhaskar.com/local/himachal/kangra/dharamshala/news/dharamshala-india-vs-south-africa-3rd-t20-weather-pitch-report-136666093.html\n",
            "Scraping article 4/10: https://www.bhaskar.com/db-original/news/pakistani-don-shahzad-bhatti-vs-lawrence-bishnoi-isi-136664183.html\n",
            "Scraping article 5/10: https://www.bhaskar.com/sports/cricket/news/suryakumar-yadav-india-vs-south-africa-t20-live-score-update-shubman-gill-hardik-pandya-abhishek-sharma-136660172.html\n",
            "Scraping article 6/10: https://www.bhaskar.com/lifestyle/news/fake-digilocker-app-meity-warning-document-theft-risk-india-136659181.html\n",
            "Scraping article 7/10: https://www.bhaskar.com/local/punjab/mohali/news/punjab-chandigarh-weather-forecast-yellow-alert-dense-fog-and-temperaturemeteorological-department-live-update-strong-winds-blow-from-tomorrow-136672970.html\n",
            "Scraping article 8/10: https://www.bhaskar.com/tech-auto/\n",
            "Scraping article 9/10: https://www.bhaskar.com/local/bihar/madhubani/news/madhubani-double-murder-case-police-link-love-affair-to-the-case-136642130.html\n",
            "Scraping article 10/10: https://www.bhaskar.com/local/jharkhand/dhanbad/news/ed-raids-in-dhanbad-136647643.html\n",
            "\n",
            "Total articles scraped from all sources: 30\n",
            "\n",
            "✅ SUCCESS: Extracted 30 headlines and saved to all_newspaper_headlines.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>Latest News Headlines - 15-12-2025</h1>\n",
              "<ul>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/sports/nba/top-stories/fact-check-is-lebron-james-son-bronny-james-expecting-a-child-with-girlfriend-parker-whitfield-how-a-viral-hoax-dragged-the-los-angeles-lakers-rookie-into-speculation/articleshow/125951095.cms\" target=\"_blank\">Fact-check: Is LeBron James’ son Bronny James expecting a child with girlfriend Parker Whitfield? How a viral hoax dragged the Los Angeles Lakers rookie into speculation</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/sports/more-sports/athletics/diamond-league-final-neeraj-chopras-event-preview-time-and-live-telecast-in-india/articleshow/123543024.cms\" target=\"_blank\">Diamond League Final: Neeraj Chopra's event preview, time and live telecast in India</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/business/platinum-rates-today\" target=\"_blank\">Check Platinum Price Per Gram in India</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/sports/cricket/news/from-michael-clarke-to-yuvraj-singh-cricketers-who-battled-cancer-with-courage/articleshow/123544122.cms\" target=\"_blank\">From Michael Clarke to Yuvraj Singh: 8 cricketers who battled cancer</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/entertainment/english/hollywood/news/bondi-beach-attack-on-hanukkah-rebel-wilson-ashton-kutcher-gal-gadot-mandy-moore-and-other-hollywood-star-condemn-shooting/articleshow/125969547.cms\" target=\"_blank\">Bondi Beach attack on Hanukkah: Rebel Wilson, Ashton Kutcher, Gal Gadot, Mandy Moore and other Hollywood stars condemn shooting</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/tv/news/hindi/exclusive-shikha-singh-makes-a-comeback-after-6-years-with-jagadhatri-says-ive-always-been-inclined-towards-a-strong-character-over-anything-else/articleshow/125969030.cms\" target=\"_blank\">Exclusive - Shikha Singh makes a comeback after 6 years with Jagadhatri; says 'I’ve always been inclined towards a strong character over anything else'</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/travel\" target=\"_blank\">Travel Guide and Information</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/city/thane\" target=\"_blank\">Thane News, Latest Thane News Headlines & Live Updates, Breaking Thane News</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/world/rest-of-world/bondi-beach-mass-shooting-from-a-holocaust-survivor-to-a-10-yr-old-child-who-the-victims-were/articleshow/125969935.cms\" target=\"_blank\">Bondi beach mass shooting: From a Holocaust survivor to a 10-yr-old child — who the victims were</a></li>\n",
              "  <li><a href=\"https://timesofindia.indiatimes.com/business/bank-holidays/is-bank-open-today\" target=\"_blank\">Is Bank Open Today?</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/opinion/editorial/\" target=\"_blank\">Editorials, Editorial Opinions, Editorial News, The Hindu Opinion</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/topic/data-point-podcast/\" target=\"_blank\">Latest Data Point podcast News, Photos, Latest News Headlines about Data Point podcast-The Hindu</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/news/international/bondi-beach-shooting-israeli-pm-netanyahu-warned-australian-counterpart-antisemitism/article70396205.ece\" target=\"_blank\">After Bondi Beach shooting, Israel’s Netanyahu accuses Australian PM of fuelling antisemitism</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/news/cities/Madurai/\" target=\"_blank\">Madurai - Latest News, Politics, Events, Entertainment</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/sci-tech/technology/intel-has-tested-chipmaking-tools-from-firm-with-sanctioned-china-unit-sources-say/article70397673.ece\" target=\"_blank\">Intel has tested chipmaking tools from firm with sanctioned China unit, sources say</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/entertainment/music/umayalpuram-k-sivaraman-performing-where-he-did-his-debut/article70395627.ece\" target=\"_blank\">Umayalpuram K. Sivaraman: Performing after 80 years at the venue where he made his debut</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/sci-tech/technology/why-are-nvidia-chips-being-sold-to-china-again-explained/article70393468.ece\" target=\"_blank\">Why are Nvidia chips being sold to China again? | Explained</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/opinion/lead/courts-must-protect-not-regulate-free-speech/article70396202.ece\" target=\"_blank\">Courts must protect, not regulate free speech</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/specials/\" target=\"_blank\">News Explainers, Timelines, Archive Stories, Lists, Story Series</a></li>\n",
              "  <li><a href=\"https://www.thehindu.com/life-and-style/motoring/\" target=\"_blank\">Automobile news today – Car and bike reviews, driving tips and auto industry news</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/db-original/explainer/\" target=\"_blank\">Explainer News in Hindi, एक्सप्लेनर समाचार, एक्सप्लेनर न्यूज़</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/national/\" target=\"_blank\">Hindi News, हिंदी समाचार, India News in Hindi, हिन्दी में समाचार, Desh</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/local/himachal/kangra/dharamshala/news/dharamshala-india-vs-south-africa-3rd-t20-weather-pitch-report-136666093.html\" target=\"_blank\">धर्मशाला में INDvsSA तीसरा टी-20 मुकाबला: ऑस्ट्रेलिया से आए टीम इंडिया के फैंस; नेटवर्क इश्यू के चलते एंट्री में दिक्कत आई - Dharamshala News</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/db-original/news/pakistani-don-shahzad-bhatti-vs-lawrence-bishnoi-isi-136664183.html\" target=\"_blank\">भास्कर एक्सक्लूसिव लॉरेंस और पाकिस्तानी डॉन शहजाद क्यों बने दुश्मन: बोला- बुलेटप्रूफ कार नहीं बचा पाएगी; गैंगस्टर-आतंकी फिर साथ, ISI का टारगेट स्लीपर सेल</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/sports/cricket/news/suryakumar-yadav-india-vs-south-africa-t20-live-score-update-shubman-gill-hardik-pandya-abhishek-sharma-136660172.html\" target=\"_blank\">भारत ने 7 विकेट से जीता तीसरा टी-20 मैच: साउथ अफ्रीका पर 2-1 की बढ़त बनाई, अभिषेक-गिल की फिफ्टी पार्टनरशिप</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/lifestyle/news/fake-digilocker-app-meity-warning-document-theft-risk-india-136659181.html\" target=\"_blank\">साइबर लिटरेसी- सरकारी चेतावनी- फर्जी DigiLocker एप से सावधान: डॉक्यूमेंट्स चोरी का रिस्क, एक्सपर्ट से जानें कैसे पहचानें असली एप</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/local/punjab/mohali/news/punjab-chandigarh-weather-forecast-yellow-alert-dense-fog-and-temperaturemeteorological-department-live-update-strong-winds-blow-from-tomorrow-136672970.html\" target=\"_blank\">पंजाब के 18 जिलों में आज घने कोहरे का अलर्ट: न्यूनतम पारा सामान्य से अधिक, कल से तेज हवाएं, लुधियाना सबसे ठंडा - Mohali News</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/tech-auto/\" target=\"_blank\">Daily Gadget News in Hindi - Dainik Bhaskar - Dainik Bhaskar</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/local/bihar/madhubani/news/madhubani-double-murder-case-police-link-love-affair-to-the-case-136642130.html\" target=\"_blank\">2 दोस्तों की बॉडी मिली, हत्या-सुसाइड में उलझी पुलिस: मधुबनी में एक पेड़ से लटका था, दूसरे की बॉडी जमीन पर थी; अफेयर का भी एंगल - Madhubani News</a></li>\n",
              "  <li><a href=\"https://www.bhaskar.com/local/jharkhand/dhanbad/news/ed-raids-in-dhanbad-136647643.html\" target=\"_blank\">धनबाद में ED की छापेमारी: कोयला कारोबारी के ठिकानों पर रेड, दस्तावेजों और वित्तीय रिकॉर्ड खंगाल रही टीम - Dhanbad News</a></li>\n",
              "</ul>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ SUCCESS: HTML output saved to headlines.html\n"
          ]
        }
      ],
      "source": [
        "!pip install newspaper3k\n",
        "!pip install lxml_html_clean\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from newspaper import Article, build\n",
        "import csv\n",
        "import time\n",
        "import pandas as pd # Import pandas for DataFrame operations\n",
        "from datetime import datetime # Import datetime for current date\n",
        "from IPython.display import HTML # Import HTML for displaying web page content\n",
        "\n",
        "# --- Configuration ---\n",
        "BASE_URL = \"https://timesofindia.indiatimes.com/\"\n",
        "OUTPUT_FILENAME = \"toi_headlines.csv\"\n",
        "OUTPUT_ALL_HEADLINES_FILENAME = \"all_newspaper_headlines.csv\"\n",
        "HTML_OUTPUT_FILENAME = \"headlines.html\" # New: HTML output filename\n",
        "\n",
        "# CRUCIAL: Realistic User-Agent is necessary\n",
        "HEADERS = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "NEWSPAPER_CONFIGS = {\n",
        "    'Times of India': {'url': 'https://timesofindia.indiatimes.com/', 'language': 'en'},\n",
        "    'The Hindu': {'url': 'https://www.thehindu.com/', 'language': 'en'},\n",
        "    'Dainik Bhaskar': {'url': 'https://www.bhaskar.com/', 'language': 'hi'}\n",
        "}\n",
        "\n",
        "def get_article_links(url, base_url):\n",
        "    \"\"\"Downloads the page and returns a set of unique article links.\"\"\"\n",
        "    print(f\"-> Collecting article links from: {url} using base URL: {base_url}\")\n",
        "    try:\n",
        "        response = requests.get(url, headers=HEADERS, timeout=15)\n",
        "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        article_links = set()\n",
        "        excluded_keywords = [\n",
        "            'javascript:', '#', '.css', '.js', '.jpg', '.png', '.gif', '.pdf',\n",
        "            'videos', 'photos', 'gallery', 'e-paper', 'epaper', 'subscribe', 'newsletter',\n",
        "            'login', 'signin', 'register', 'terms-of-use', 'privacy-policy', 'contact-us', 'about-us',\n",
        "            'advertise', 'careers', 'sitemap', 'authors', 'topics', 'tags', 'archives'\n",
        "        ]\n",
        "\n",
        "        for a_tag in soup.find_all('a', href=True):\n",
        "            href = a_tag['href']\n",
        "            full_link = \"\"\n",
        "\n",
        "            # Construct full URL if relative\n",
        "            if href.startswith('http') and base_url.split('//')[1].split('/')[0] in href:\n",
        "                full_link = href\n",
        "            elif href.startswith('/') and not href.startswith('//'): # Relative URL\n",
        "                full_link = base_url.rstrip('/') + href\n",
        "\n",
        "            # Filter out obvious non-article links and duplicates\n",
        "            if full_link and not any(keyword in full_link for keyword in excluded_keywords):\n",
        "                if full_link != base_url and len(full_link) > len(base_url) + 5: # Avoid just base URL and very short links\n",
        "                    article_links.add(full_link)\n",
        "\n",
        "        print(f\"-> Found {len(article_links)} unique potential article links.\")\n",
        "        return article_links\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"ERROR: Could not fetch {url}. Reason: {e}\")\n",
        "        return set()\n",
        "\n",
        "def scrape_article_data(links, language, limit=10):\n",
        "    \"\"\"Scrapes the title, date, and URL for each article link, up to a specified limit.\"\"\"\n",
        "    scraped_data = []\n",
        "    # Convert set to list and take only the first 'limit' items\n",
        "    links_to_process = list(links)[:limit]\n",
        "\n",
        "    print(f\"-> Scraping data for the first {len(links_to_process)} articles...\")\n",
        "    for i, link in enumerate(links_to_process):\n",
        "        print(f\"Scraping article {i+1}/{len(links_to_process)}: {link}\")\n",
        "\n",
        "        try:\n",
        "            # Use newspaper3k for intelligent article content extraction\n",
        "            article = Article(link, language=language)\n",
        "            article.download()\n",
        "            article.parse()\n",
        "\n",
        "            scraped_data.append({\n",
        "                \"Title\": article.title,\n",
        "                \"Publish_Date\": str(article.publish_date), # Convert datetime object to string\n",
        "                \"URL\": link\n",
        "            })\n",
        "\n",
        "            # Introduce a short, polite delay between requests\n",
        "            time.sleep(1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"WARNING: Failed to process article {link}. Skipping. Error: {e}\")\n",
        "            time.sleep(1) # Still pause if an error occurs\n",
        "            continue\n",
        "\n",
        "    return scraped_data\n",
        "\n",
        "def save_to_csv(data, filename):\n",
        "    \"\"\"Saves the list of dictionaries to a CSV file.\"\"\"\n",
        "    if not data:\n",
        "        print(\"No data to save.\")\n",
        "        return\n",
        "\n",
        "    # Use the keys of the first dictionary as the field names (headers)\n",
        "    fieldnames = data[0].keys()\n",
        "\n",
        "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        writer.writeheader() # Write the header row\n",
        "        writer.writerows(data) # Write all the data rows\n",
        "\n",
        "    print(f\"\\n✅ SUCCESS: Extracted {len(data)} headlines and saved to {filename}\")\n",
        "\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "if __name__ == \"__main__\":\n",
        "    all_scraped_data = []\n",
        "\n",
        "    for newspaper_name, config in NEWSPAPER_CONFIGS.items():\n",
        "        newspaper_url = config['url']\n",
        "        newspaper_language = config['language']\n",
        "\n",
        "        print(f\"\\n=== Processing {newspaper_name} ===\")\n",
        "\n",
        "        # 1. Get article links for the current newspaper\n",
        "        article_links = get_article_links(newspaper_url, newspaper_url)\n",
        "\n",
        "        if article_links:\n",
        "            # 2. Scrape article data for the current newspaper, with language and limit\n",
        "            newspaper_data = scrape_article_data(article_links, newspaper_language, limit=10)\n",
        "\n",
        "            # 3. Add 'Source' column to each article\n",
        "            for article in newspaper_data:\n",
        "                article['Source'] = newspaper_name\n",
        "\n",
        "            # 4. Accumulate all scraped data\n",
        "            all_scraped_data.extend(newspaper_data)\n",
        "        else:\n",
        "            print(f\"No article links found for {newspaper_name}.\")\n",
        "\n",
        "    print(f\"\\nTotal articles scraped from all sources: {len(all_scraped_data)}\")\n",
        "\n",
        "    # Save the combined results to a single CSV\n",
        "    save_to_csv(all_scraped_data, OUTPUT_ALL_HEADLINES_FILENAME)\n",
        "\n",
        "    # Load the combined data into a DataFrame\n",
        "    df_all_headlines = pd.read_csv(OUTPUT_ALL_HEADLINES_FILENAME)\n",
        "\n",
        "    # Display headlines in an HTML page with hyperlinks\n",
        "    current_date = datetime.now().strftime('%d-%m-%Y')\n",
        "\n",
        "    html_content_parts = [\n",
        "        f\"<h1>Latest News Headlines - {current_date}</h1>\\n\",\n",
        "        \"<ul>\\n\"\n",
        "    ]\n",
        "\n",
        "    for index, row in df_all_headlines.iterrows():\n",
        "        title = row['Title']\n",
        "        url = row['URL']\n",
        "        html_content_parts.append(f\"  <li><a href=\\\"{url}\\\" target=\\\"_blank\\\">{title}</a></li>\\n\")\n",
        "\n",
        "    html_content_parts.append(\"</ul>\")\n",
        "\n",
        "    new_html_content = \"\".join(html_content_parts)\n",
        "    display(HTML(new_html_content))\n",
        "\n",
        "    # New: Save the HTML content to a file\n",
        "    with open(HTML_OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n",
        "        f.write(new_html_content)\n",
        "    print(f\"\\n✅ SUCCESS: HTML output saved to {HTML_OUTPUT_FILENAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "K-uj7l2Tj9KD"
      }
    }
  ]
}